---
title: "Questionnaires to Unlock the Power of ReDem"
description: "Enhance fraud detection in online surveys with strategic design to maximize the effectiveness of ReDem"
icon: "clipboard-check"
iconType: "regular"
---

Learn how to enhance fraud detection in online surveys by strategically designing questionnaires that maximize the effectiveness of our advanced technological quality checks.

If your questionnaire doesn’t meet these criteria, consider enhancing it for better results.&#x20;

Open-ended questions are particularly effective for ensuring data quality. We recommend to use at least **two mandatory open-ended questions** that all respondents must answer. The open-ended questions can be added for quality control purposes only and do not need to be evaluated.

### Open-Ended Questions

* **Mandatory:** Fraudsters often avoid answering open-ended questions if they can, and inattentive participants tend to skip them too. Therefore, making these questions mandatory is crucial. If designed appropriately (e.g., not too many or overly difficult questions), the dropouts caused by mandatory open-ended questions can actually improve data quality by filtering out disengaged participants.

* **AI-Friendly:** Open-ended questions should be well suited for AI-assisted quality checks. They need to provide a frame of reference for the AI to assess the meaningfulness of responses. Questions like "Would you like to tell us anything else?" are less effective because they lack a content framework, making it difficult for AI to evaluate answer quality.

* **Detecting AI-Generated Responses:** To identify AI-generated responses, questions that are emotional or opinion-based are particularly useful, as chatbots struggle to authentically replicate personal opinions or emotional expressions.

* **Strategic Placement:** For thorough quality assessment, it is recommended to include at least two open-ended questions in a questionnaire, strategically placed, such as one at the beginning and one at the end. In longer surveys, a respondent may momentarily lose focus and provide a nonsensical answer, but if this occurs more than once, it significantly increases the likelihood of poor data quality. This distribution also helps evaluate participant engagement throughout the survey. Additionally, analyzing duplicates or partial duplicates within a single interview, as well as across multiple interviews, can further aid in quality assessment.

### Grid-Questions

* We recommend to include at least **1 grid question** with at least **7 items** (the more, the better) and in each case at least **4 attribute values** (e.g., a Likert scale).

* **Sufficient Number of Statements:** To accurately determine whether responses are genuine or arbitrary, a grid question should include a sufficient number of statements. Our experience suggests a minimum of seven statements for this purpose.

* **Appropriate Number of Options:** The number of response options should be inversely related to the number of statements in the grid. As the number of statements increases, fewer options are needed. We recommend at least three options to ensure reliable quality checks.

* **Inverted Statements:** Statements should be phrased to create potential inconsistencies or contradictions if answered uniformly. This can be achieved by including both positive and negative statements about the subject being examined, ensuring that the responses require thoughtful consideration.

### Time Durations

* Capture the **total interview duration** to identify unusually fast or slow responses.

* Consider measuring durations for specific sections (e.g., matrix questions with substantial text or open-ended responses) for more insight.

* Avoid timing short yes/no questions or demographic inquiries, as they are too brief for meaningful analysis.

* If interruptions are possible during survey completion, ensure they don’t interfere with time tracking.